\documentclass{article}

\usepackage{hyperref}
\usepackage{amsmath}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\dd}[1]{\mathrm{d}#1}


\title{ML Questions}
\author{Jyotirmoy Banerjee}
\begin{document}
\maketitle

\section{Machine learning questions}

\begin{enumerate}
\item If you reduce the size of the training set, which one will reduce, bias or variance? Ans - Bias will increase with less data, hence variance will decrease.
\item Given three data points 1, 2 and 3, explain bootstrapping? Ans - (3,1,3), (2,3,1) $\cdots$ (2,2,1).
\item Let decision tree has two variables $x_1$ and $x_2$. When you move down the tree, is it true that the variables have to be picked alternately? Ans - Not necessarily. 
\item Tree pruning, why it is important? Why don't we grow the tree only so long as the decrease in the RSS (residual sum of square) due to each split exceeds some threshold? Ans - Tree split is a greedy approach and using the mentioned criteria, it may stops too early, leading to a small tree. A seemingly worthless split early on, might be followed by a very good split.
\item Why tree pruning is not important in bagging approaches? Ans - Pruning is used to reduce variance. In bagging averaging over the trees helps reduce variance.
\end{enumerate}

\section{Data structure and algorithm questions}

\begin{enumerate}
\item Verify if, $n^{4/3} = O(n \log n)$, True or False? Ans - False. Hint - If $n = 1000, n^{4/3} > O(n \log n)$.
\end{enumerate}

\end{document}